version: "3.8"

services:
  kafka:
    image: apache/kafka:3.7.2
    ports:
      - "9092:9092"
    environment:
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_LOG_DIRS=/var/lib/kafka/data
      - KAFKA_NUM_PARTITIONS=3
      - CLUSTER_ID=5L6g3nShT-eMCtK--X86sw
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 10s
      timeout: 10s
      retries: 12

  kafka-init:
    image: apache/kafka:3.7.2
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./kafka/create-topics.sh:/scripts/create-topics.sh:ro
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
    entrypoint: ["/bin/bash", "/scripts/create-topics.sh"]
    restart: "no"

  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.2
    ports:
      - "18080:8080"
    depends_on:
      - kafka
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_READONLY=false
      - DYNAMIC_CONFIG_ENABLED=true

  postgres:
    image: pgduckdb/pgduckdb:16-v1.1.1
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=analytics
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d analytics"]
      interval: 10s
      timeout: 5s
      retries: 10

  metadata-redis:
    image: redis:7.2-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 6

  risingwave:
    image: risingwavelabs/risingwave:v1.7.0
    ports:
      - "4566:4566"
    depends_on:
      - kafka
      - postgres

  risingwave-init:
    image: postgres:16.3
    depends_on:
      risingwave:
        condition: service_started
      kafka:
        condition: service_healthy
    volumes:
      - ./risingwave/init.sql:/init.sql:ro
    entrypoint:
      - /bin/bash
      - -c
      - |
        set -e
        until pg_isready -h risingwave -p 4566 -U root; do
          echo "waiting for risingwave..."
          sleep 3
        done
        until (echo > /dev/tcp/kafka/9092) >/dev/null 2>&1; do
          echo "waiting for kafka..."
          sleep 3
        done
        psql -h risingwave -p 4566 -U root -d dev -f /init.sql
    restart: "no"

  producer:
    build:
      context: ./producer
    depends_on:
      kafka-init:
        condition: service_completed_successfully
    environment:
      - EVENTS_PER_SEC=10
      - MIX_ZEEK_PERCENT=60
      - MIX_SURICATA_PERCENT=40
      - SEED=42
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_TOPIC=raw.security_events

  airflow-init:
    image: apache/airflow:2.9.2-python3.11
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=H8oF2K4U7b8C3jY2nG9YF0pI5J6kT8mP1qR2sX3u4vE=
      - AIRFLOW__WEBSERVER__SECRET_KEY=airflowsecret
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin
      - _AIRFLOW_WWW_USER_FIRSTNAME=Admin
      - _AIRFLOW_WWW_USER_LASTNAME=User
      - _AIRFLOW_WWW_USER_EMAIL=azka.ghulam13@gmail.com
      - PIP_EXTRA_REQUIREMENTS=apache-airflow-providers-postgres==5.11.0 soda-core==3.4.0 soda-core-postgres==3.4.0 redis==5.0.6
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/include:/opt/airflow/include
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db migrate
        airflow users create \
          --role Admin \
          --username "$$_AIRFLOW_WWW_USER_USERNAME" \
          --password "$$_AIRFLOW_WWW_USER_PASSWORD" \
          --firstname "$$_AIRFLOW_WWW_USER_FIRSTNAME" \
          --lastname "$$_AIRFLOW_WWW_USER_LASTNAME" \
          --email "$$_AIRFLOW_WWW_USER_EMAIL"
    restart: "no"

  airflow-webserver:
    image: apache/airflow:2.9.2-python3.11
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    ports:
      - "8088:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=H8oF2K4U7b8C3jY2nG9YF0pI5J6kT8mP1qR2sX3u4vE=
      - AIRFLOW__WEBSERVER__SECRET_KEY=airflowsecret
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW_CONN_ANALYTICS_DB=postgresql://etl_runner:etl_runner@postgres:5432/analytics
      - METADATA_REDIS_HOST=metadata-redis
      - METADATA_REDIS_PORT=6379
      - METADATA_REDIS_DB=0
      - METADATA_REDIS_KEY=pipelines
      - SODA_POSTGRES_HOST=postgres
      - SODA_POSTGRES_PORT=5432
      - SODA_POSTGRES_DB=analytics
      - SODA_POSTGRES_USERNAME=etl_runner
      - SODA_POSTGRES_PASSWORD=etl_runner
      - PIP_EXTRA_REQUIREMENTS=apache-airflow-providers-postgres==5.11.0 soda-core==3.4.0 soda-core-postgres==3.4.0 redis==5.0.6
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/include:/opt/airflow/include
    command: webserver

  airflow-scheduler:
    image: apache/airflow:2.9.2-python3.11
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=H8oF2K4U7b8C3jY2nG9YF0pI5J6kT8mP1qR2sX3u4vE=
      - AIRFLOW__WEBSERVER__SECRET_KEY=airflowsecret
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW_CONN_ANALYTICS_DB=postgresql://etl_runner:etl_runner@postgres:5432/analytics
      - METADATA_REDIS_HOST=metadata-redis
      - METADATA_REDIS_PORT=6379
      - METADATA_REDIS_DB=0
      - METADATA_REDIS_KEY=pipelines
      - SODA_POSTGRES_HOST=postgres
      - SODA_POSTGRES_PORT=5432
      - SODA_POSTGRES_DB=analytics
      - SODA_POSTGRES_USERNAME=etl_runner
      - SODA_POSTGRES_PASSWORD=etl_runner
      - PIP_EXTRA_REQUIREMENTS=apache-airflow-providers-postgres==5.11.0 soda-core==3.4.0 soda-core-postgres==3.4.0 redis==5.0.6
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/include:/opt/airflow/include
    command: scheduler

  superset:
    image: apache/superset:4.0.1
    ports:
      - "8089:8088"
    environment:
      - SUPERSET_SECRET_KEY=supersetsecret
      - SUPERSET_LOAD_EXAMPLES=no
      - SUPERSET_ENV=production
      - SUPERSET_SQLALCHEMY_DATABASE_URI=sqlite:////var/lib/superset/superset.db
      - SQLALCHEMY_DATABASE_URI=sqlite:////var/lib/superset/superset.db
    volumes:
      - superset_data:/var/lib/superset
      - ./superset/superset_config.py:/app/pythonpath/superset_config.py:ro
    depends_on:
      - postgres

  superset-init:
    image: apache/superset:4.0.1
    depends_on:
      - superset
    environment:
      - SUPERSET_SECRET_KEY=supersetsecret
      - SUPERSET_LOAD_EXAMPLES=no
      - SUPERSET_ENV=production
      - SUPERSET_SQLALCHEMY_DATABASE_URI=sqlite:////var/lib/superset/superset.db
      - SQLALCHEMY_DATABASE_URI=sqlite:////var/lib/superset/superset.db
    volumes:
      - superset_data:/var/lib/superset
      - ./superset/superset_config.py:/app/pythonpath/superset_config.py:ro
    entrypoint: /bin/bash
    command:
      - -c
      - |
        superset db upgrade
        superset fab create-admin \
          --username admin \
          --firstname Admin \
          --lastname User \
          --email azka.ghulam13@gmail.com \
          --password admin
        superset init
    restart: "no"

volumes:
  kafka_data:
  postgres_data:
  superset_data:
